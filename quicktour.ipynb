{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4886c870",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T13:55:11.251831Z",
     "start_time": "2022-07-14T13:55:08.523738Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d909e0be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T13:58:00.680073Z",
     "start_time": "2022-07-14T13:55:42.830451Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c638c5ac8c04e27847e9a029dfb0618",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/629 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b74e0289e90847adb3432bc07099aef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/255M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f11720839484e9ea934a1f903779535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93247e29b81e490d80748124c78e7bfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pipeline will help to call pre-trained model\n",
    "classifier = pipeline('sentiment-analysis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ef10e50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T14:06:05.615519Z",
     "start_time": "2022-07-14T14:06:05.466933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEGATIVE', 'score': 0.9991381168365479}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier('I am neither happy nor sad at the moment!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0db61f7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-14T14:14:36.167555Z",
     "start_time": "2022-07-14T14:14:36.105345Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label: POSITIVE, score: 0.997\n",
      "label: NEGATIVE, score: 0.598\n"
     ]
    }
   ],
   "source": [
    "results = classifier(['I am an RCB fan', 'We hope you don\"t love it'])\n",
    "\n",
    "for res in results:\n",
    "    print(f\"label: {res['label']}, score: {round(res['score'],3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5905ef",
   "metadata": {},
   "source": [
    "The second sentence has been classified as negative and score is fairly neutral.\n",
    "\n",
    "By default, the model downloaded for this pipeline is called \"distillbert-base-uncased-finetuned-sst-2-english\". It uses DistillBERT architecture and has been fine-tuned on a dataset called SST-2 for the sentiment analysis task.\n",
    "\n",
    "If we want to use another model, for instance, one that has been trained on French data. We can search through the model hub that gathers models pretrained on a lot of data by research labs, but also community models (usually fine-tuned versions of those big models on a specific dataset). Applying the tags \"French\" and \"text-classification\" gives back a suggestion \"nlptown/bert-base-multilingual-uncased-sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8948576",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T04:20:32.362416Z",
     "start_time": "2022-07-15T04:16:06.078320Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a2cedabf8334675ae9b4dbc434959fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/638M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e96bfaa7457418fac8163d11b5def9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8b19db3bb5f42bca0d270601c2d8c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/851k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a748e3b4f743412b858fb7b3658ee3e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_classifier = pipeline('sentiment-analysis', \n",
    "                          model='nlptown/bert-base-multilingual-uncased-sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31bc7e3f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T04:21:54.623274Z",
     "start_time": "2022-07-15T04:21:54.521597Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '3 stars', 'score': 0.2779175341129303}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classifier('Bonjour')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "412bb3aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T04:22:36.149893Z",
     "start_time": "2022-07-15T04:22:36.078567Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '1 star', 'score': 0.4849565625190735}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_classifier(\"Nous espÃ©rons que vous ne l'aimez pas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffcb3c",
   "metadata": {},
   "source": [
    "This classifier can now deal with texts in English, French, but also Dutch, German, Italian and Spanish, we can replace that name by a local folder where you have saved a pretrained model. We can also pass a model object and its assosciated tokenizer.\n",
    "\n",
    "We will need two classes for this, the first is \"AutoTokenizer\", which we will use to download the tokenizer assosciated to the model we picked and instantiate it. The second is \"AutoModelForSequenceClassification\" or ( TFAutoModeForSequenceClassification if we are using tensorflow), which we will use to download the model itself. Note that if we were using the library on an another task, the class of the model would change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0080f4cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:14:50.878476Z",
     "start_time": "2022-07-15T07:14:50.871399Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5277bdf4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:28:53.949255Z",
     "start_time": "2022-07-15T07:28:32.103423Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "All the weights of TFBertForSequenceClassification were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "model_name = 'nlptown/bert-base-multilingual-uncased-sentiment'\n",
    "# This model exists only in PyTorch, so we use the 'from_pt' flag to import that model in TensorFlow\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(model_name, from_pt = True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "classifier = pipeline(\"sentiment-analysis\", model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "788d9ddc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:30:31.480033Z",
     "start_time": "2022-07-15T07:30:31.266805Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '4 stars', 'score': 0.4229269027709961}]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier(\"I am a good boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "908c215b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:47:43.008838Z",
     "start_time": "2022-07-15T07:47:42.998873Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = tokenizer(\"I am a good boy, not a bad boy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73da03b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T07:47:43.477463Z",
     "start_time": "2022-07-15T07:47:43.468762Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [101, 151, 10345, 143, 12050, 14140, 117, 10497, 143, 12428, 14140, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs\n",
    "# input_ids: each word is given a token id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b87683c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T09:11:24.192550Z",
     "start_time": "2022-07-15T09:11:24.145260Z"
    }
   },
   "outputs": [],
   "source": [
    "# padding is done to make all sentences equal\n",
    "# truncation will remove any spaces\n",
    "# max length of embedding would be 512\n",
    "tf_batch = tokenizer(\n",
    "                    ['We are very happy to show this library',\n",
    "                     'We hope you do not hate it'],\n",
    "                    padding=True, \n",
    "                    truncation=True, \n",
    "                    max_length=512, \n",
    "                    return_tensors='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eca17486",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T09:13:16.232969Z",
     "start_time": "2022-07-15T09:13:16.224266Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: [[101, 11312, 10320, 12495, 19308, 10114, 11391, 10372, 13299, 102], [101, 11312, 18763, 10855, 10154, 10497, 39487, 10197, 102, 0]]\n",
      "token_type_ids: [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "attention_mask: [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 0]]\n"
     ]
    }
   ],
   "source": [
    "for key, value in tf_batch.items():\n",
    "    print(f\"{key}: {value.numpy().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16fe4f43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
